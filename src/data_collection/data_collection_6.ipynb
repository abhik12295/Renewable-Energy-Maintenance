{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8664246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def fetch_reddit_sentiment(subreddits=[\"renewableenergy\", \"energy\", \"Texas\"], \n",
    "                           keywords=[\"Texas wind\", \"Texas solar\"], \n",
    "                           limit=100):\n",
    "    try:\n",
    "        \n",
    "        client_id = os.getenv(\"reddit_client_id\")\n",
    "        client_secret = os.getenv(\"reddit_client_secret\")\n",
    "        user_agent = os.getenv(\"reddit_user_agent\")\n",
    "        username = os.getenv(\"username\")\n",
    "        password = os.getenv(\"password\")\n",
    "        username = username.strip('\",\\' ')\n",
    "        password = password\n",
    "        # Authenticate with Reddit\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            user_agent=user_agent,\n",
    "            username=username,\n",
    "            password=password\n",
    "        )\n",
    "        \n",
    "        # Sentiment analyzer\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        data = []\n",
    "\n",
    "        # Loop through subreddits and fetch matching posts\n",
    "        for subreddit in subreddits:\n",
    "            query = \" OR \".join(keywords)\n",
    "            for submission in reddit.subreddit(subreddit).search(query, limit=limit):\n",
    "                combined_text = (submission.title or \"\") + \" \" + (submission.selftext or \"\")\n",
    "                sentiment = analyzer.polarity_scores(combined_text)\n",
    "                data.append({\n",
    "                    'subreddit': subreddit,\n",
    "                    'date': pd.to_datetime(submission.created_utc, unit='s'),\n",
    "                    'text': combined_text,\n",
    "                    'sentiment_score': sentiment['compound'],\n",
    "                    'title': submission.title,\n",
    "                    'url': submission.url\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Reddit data: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c9cd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>renewableenergy</td>\n",
       "      <td>2025-01-13 15:02:26</td>\n",
       "      <td>Texas leads U.S. in wind, solar, No. 2 in batt...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>Texas leads U.S. in wind, solar, No. 2 in batt...</td>\n",
       "      <td>https://www.chron.com/news/houston-texas/artic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>renewableenergy</td>\n",
       "      <td>2025-05-02 04:12:44</td>\n",
       "      <td>Texas House passes bill to require recycling o...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Texas House passes bill to require recycling o...</td>\n",
       "      <td>https://pv-magazine-usa.com/2025/05/01/texas-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>renewableenergy</td>\n",
       "      <td>2025-04-17 15:56:10</td>\n",
       "      <td>Wind, solar, and battery storage projects are ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Wind, solar, and battery storage projects are ...</td>\n",
       "      <td>https://yaleclimateconnections.org/2025/03/cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>renewableenergy</td>\n",
       "      <td>2025-03-10 20:17:45</td>\n",
       "      <td>Texas broke its solar, wind, and battery recor...</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>Texas broke its solar, wind, and battery recor...</td>\n",
       "      <td>https://www.canarymedia.com/articles/clean-ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>renewableenergy</td>\n",
       "      <td>2022-03-22 20:14:11</td>\n",
       "      <td>Texas has enough solar and wind planned to per...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Texas has enough solar and wind planned to per...</td>\n",
       "      <td>https://pv-magazine-usa.com/2022/03/22/solar-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                date  \\\n",
       "0  renewableenergy 2025-01-13 15:02:26   \n",
       "1  renewableenergy 2025-05-02 04:12:44   \n",
       "2  renewableenergy 2025-04-17 15:56:10   \n",
       "3  renewableenergy 2025-03-10 20:17:45   \n",
       "4  renewableenergy 2022-03-22 20:14:11   \n",
       "\n",
       "                                                text  sentiment_score  \\\n",
       "0  Texas leads U.S. in wind, solar, No. 2 in batt...           0.2732   \n",
       "1  Texas House passes bill to require recycling o...           0.0000   \n",
       "2  Wind, solar, and battery storage projects are ...           0.0000   \n",
       "3  Texas broke its solar, wind, and battery recor...          -0.4215   \n",
       "4  Texas has enough solar and wind planned to per...           0.0000   \n",
       "\n",
       "                                               title  \\\n",
       "0  Texas leads U.S. in wind, solar, No. 2 in batt...   \n",
       "1  Texas House passes bill to require recycling o...   \n",
       "2  Wind, solar, and battery storage projects are ...   \n",
       "3  Texas broke its solar, wind, and battery recor...   \n",
       "4  Texas has enough solar and wind planned to per...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.chron.com/news/houston-texas/artic...  \n",
       "1  https://pv-magazine-usa.com/2025/05/01/texas-h...  \n",
       "2  https://yaleclimateconnections.org/2025/03/cle...  \n",
       "3  https://www.canarymedia.com/articles/clean-ene...  \n",
       "4  https://pv-magazine-usa.com/2022/03/22/solar-a...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_reddit_sentiment()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2499cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   subreddit        300 non-null    object        \n",
      " 1   date             300 non-null    datetime64[ns]\n",
      " 2   text             300 non-null    object        \n",
      " 3   sentiment_score  300 non-null    float64       \n",
      " 4   title            300 non-null    object        \n",
      " 5   url              300 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "213f2ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2732,\n",
       " 0.34,\n",
       " 0.4215,\n",
       " 0.4019,\n",
       " 0.8612,\n",
       " 0.3612,\n",
       " 0.7003,\n",
       " 0.5719,\n",
       " 0.8805,\n",
       " 0.4939,\n",
       " 0.0772,\n",
       " 0.5859,\n",
       " 0.5994,\n",
       " 0.9212,\n",
       " 0.9505,\n",
       " 0.9994,\n",
       " 0.9908,\n",
       " 0.8442,\n",
       " 0.8708,\n",
       " 0.6369,\n",
       " 0.2023,\n",
       " 0.5106,\n",
       " 0.3412,\n",
       " 0.1531,\n",
       " 0.25,\n",
       " 0.7845,\n",
       " 0.4404,\n",
       " 0.6705,\n",
       " 0.7184,\n",
       " 0.8316,\n",
       " 0.5267,\n",
       " 0.6864,\n",
       " 0.3818,\n",
       " 0.3197,\n",
       " 0.6486,\n",
       " 0.9153,\n",
       " 0.7227,\n",
       " 0.8889,\n",
       " 0.3182,\n",
       " 0.6875,\n",
       " 0.6249,\n",
       " 0.6908,\n",
       " 0.0516,\n",
       " 0.7305,\n",
       " 0.7,\n",
       " 0.885,\n",
       " 0.8979,\n",
       " 0.6432,\n",
       " 0.9573,\n",
       " 0.6597,\n",
       " 0.0258,\n",
       " 0.9974,\n",
       " 0.5396,\n",
       " 0.1779,\n",
       " 0.0754,\n",
       " 0.8891,\n",
       " 0.8206,\n",
       " 0.7672,\n",
       " 0.6124,\n",
       " 0.743,\n",
       " 0.6808,\n",
       " 0.09,\n",
       " 0.1027,\n",
       " 0.8992,\n",
       " 0.9201,\n",
       " 0.8315,\n",
       " 0.1933,\n",
       " 0.8779,\n",
       " 0.9633,\n",
       " 0.7506,\n",
       " 0.7783,\n",
       " 0.5647,\n",
       " 0.7263,\n",
       " 0.3384,\n",
       " 0.9886,\n",
       " 0.5571,\n",
       " 0.7906,\n",
       " 0.4588,\n",
       " 0.6416]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_copy['sentiment_score'].unique().tolist()\n",
    "y = [i for i in x if i>0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5037c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd().rsplit(\"\\\\\", 2)[0]\n",
    "df_copy.to_csv(os.path.join(os.getcwd().rsplit(\"\\\\\", 2)[0], r\"data\\raw\", \"reddit_sentiment_raw.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347f630",
   "metadata": {},
   "source": [
    "## Fetch News Sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c35e1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "urls = r\"https://www.texastribune.org/topics/energy/\"\n",
    "keywords = [\"wind\", \"solar\"]\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2dc6b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "def fetch_news_sentiment(urls=[\"https://www.texastribune.org/topics/energy/\"], keywords=[\"wind\",\"renewable energy\", \"solar\"], max_pages=20):\n",
    "    try:\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        data = []\n",
    "        for url in urls:\n",
    "            for page in range(1, max_pages + 1):\n",
    "                paged_url = f\"{url}?page={page}\" if page > 1 else url\n",
    "                response = requests.get(paged_url)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                articles = soup.find_all('article')\n",
    "                for article in articles:\n",
    "                    text = article.get_text()\n",
    "                    date_match = re.search(r'(JAN.|FEB.|MARCH|APRIL|MAY|JUNE|JULY|AUG.|SEP.|OCT.|NOV.|DEC.)[A-Z]*\\.?\\s+\\d{1,2},\\s+\\d{4}', text)\n",
    "                    if date_match:\n",
    "                        try:\n",
    "                            date = parser.parse(date_match.group())\n",
    "                        except Exception:\n",
    "                            date = pd.to_datetime('now')\n",
    "                    else:\n",
    "                        date = pd.to_datetime('now')\n",
    "                    if (pd.Timestamp.now() - date).days <= 365*10:\n",
    "                        if any(keyword.lower() in text.lower() for keyword in keywords):\n",
    "                            sentiment = analyzer.polarity_scores(text)\n",
    "                            data.append({\n",
    "                                'date': date,\n",
    "                                'text': text,\n",
    "                                'sentiment_score': sentiment['compound']\n",
    "                            })\n",
    "        df = pd.DataFrame(data)\n",
    "        if len(df) < 10:\n",
    "            print(\"Warning: Less than 10 records found.\")\n",
    "        return df.head(10)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news data: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35aedc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def fetch_news_sentiment(\n",
    "    urls=[\"https://www.texastribune.org/topics/energy/\"],\n",
    "    keywords=[\"wind\", \"renewable energy\", \"solar\"],\n",
    "    years_back=10\n",
    "):\n",
    "    try:\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        data = []\n",
    "        cutoff = pd.Timestamp.now() - pd.Timedelta(days=365 * years_back)\n",
    "\n",
    "        for url in urls:\n",
    "            page = 1\n",
    "            stop_paging = False\n",
    "            while not stop_paging:\n",
    "                paged_url = f\"{url}?page={page}\" if page > 1 else url\n",
    "                response = requests.get(paged_url)\n",
    "                if not response.ok:\n",
    "                    break\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                articles = soup.find_all('article')\n",
    "                if not articles:\n",
    "                    break\n",
    "\n",
    "                for article in articles:\n",
    "                    text = article.get_text()\n",
    "                    # Find a date in text\n",
    "                    date_match = re.search(r'(JAN\\.|FEB\\.|MARCH|APRIL|MAY|JUNE|JULY|AUG\\.|SEP\\.|OCT\\.|NOV\\.|DEC\\.)[A-Z]*\\.?\\s+\\d{1,2},\\s+\\d{4}', text)\n",
    "                    if date_match:\n",
    "                        try:\n",
    "                            date = parser.parse(date_match.group())\n",
    "                        except Exception:\n",
    "                            date = pd.to_datetime('now')\n",
    "                    else:\n",
    "                        date = pd.to_datetime('now')\n",
    "\n",
    "                    # Only analyze if date is within range\n",
    "                    if date >= cutoff:\n",
    "                        if any(keyword.lower() in text.lower() for keyword in keywords):\n",
    "                            sentiment = analyzer.polarity_scores(text)\n",
    "                            data.append({\n",
    "                                'date': date,\n",
    "                                'text': text,\n",
    "                                'sentiment_score': sentiment['compound']\n",
    "                            })\n",
    "                    else:\n",
    "                        # If ALL articles are old, we can stop after this page\n",
    "                        stop_paging = True   # Will break outer while after for loop\n",
    "\n",
    "                page += 1  # move to next page\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news data: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf6a17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = fetch_news_sentiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eaa86c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2025-07-22 20:34:51.914708</td>\n",
       "      <td>\\n\\n\\nThe Green Mile\\n\\n\\n    By Ben Philpott,...</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2025-07-22 20:34:51.915693</td>\n",
       "      <td>\\n\\n\\nA Conversation with T. Boone Pickens\\n\\n...</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2025-07-22 20:34:52.932165</td>\n",
       "      <td>\\n\\n\\nWind in the Wires\\n\\n\\n    By Kate Galbr...</td>\n",
       "      <td>-0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2025-07-22 20:34:52.933169</td>\n",
       "      <td>\\n\\n\\nTribWeek: In Case You Missed It\\n\\n\\n   ...</td>\n",
       "      <td>0.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2025-07-22 20:34:52.935154</td>\n",
       "      <td>\\n\\n\\nDon't Blow It\\n\\n\\n    By Kate Galbraith...</td>\n",
       "      <td>0.6757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "168 2025-07-22 20:34:51.914708   \n",
       "169 2025-07-22 20:34:51.915693   \n",
       "170 2025-07-22 20:34:52.932165   \n",
       "171 2025-07-22 20:34:52.933169   \n",
       "172 2025-07-22 20:34:52.935154   \n",
       "\n",
       "                                                  text  sentiment_score  \n",
       "168  \\n\\n\\nThe Green Mile\\n\\n\\n    By Ben Philpott,...           0.5423  \n",
       "169  \\n\\n\\nA Conversation with T. Boone Pickens\\n\\n...          -0.0772  \n",
       "170  \\n\\n\\nWind in the Wires\\n\\n\\n    By Kate Galbr...          -0.0258  \n",
       "171  \\n\\n\\nTribWeek: In Case You Missed It\\n\\n\\n   ...           0.9531  \n",
       "172  \\n\\n\\nDon't Blow It\\n\\n\\n    By Kate Galbraith...           0.6757  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()\n",
    "df_news.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9454ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             173 non-null    datetime64[ns]\n",
      " 1   text             173 non-null    object        \n",
      " 2   sentiment_score  173 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd().rsplit(\"\\\\\", 2)[0]\n",
    "df_news.to_csv(os.path.join(os.getcwd().rsplit(\"\\\\\", 2)[0], r\"data\\raw\", \"news_sentiment_raw.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
